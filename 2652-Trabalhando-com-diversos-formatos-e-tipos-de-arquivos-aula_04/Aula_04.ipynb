{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.mkdirs(\"/FileStore/tables/arquivos_curso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo um arquivo JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"/FileStore/tables/arquivos_curso/PNSB.json\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"D1C\",\"cod_regiao\") \\\n",
    "       .withColumnRenamed(\"D1N\",\"regiao\") \\\n",
    "       .withColumnRenamed(\"D2C\",\"cod_variavel\") \\\n",
    "       .withColumnRenamed(\"D2N\",\"variavel\") \\\n",
    "       .withColumnRenamed(\"D3C\",\"cod_ano\") \\\n",
    "       .withColumnRenamed(\"D3N\",\"ano\") \\\n",
    "       .withColumnRenamed(\"D4C\",\"cod_doenca\") \\\n",
    "       .withColumnRenamed(\"D4N\",\"doenca\") \\\n",
    "       .withColumnRenamed(\"MC\",\"cod_medida\") \\\n",
    "       .withColumnRenamed(\"MN\",\"medida\") \\\n",
    "       .withColumnRenamed(\"NC\",\"cod_nivel_territorial\") \\\n",
    "       .withColumnRenamed(\"NN\",\"nivel_territorial\") \\\n",
    "       .withColumnRenamed(\"V\",\"valor\") \n",
    "\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df.valor!='Valor')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "df_new = df.withColumn(\"cod_regiao\", col(\"cod_regiao\").cast(IntegerType())) \\\n",
    "           .withColumn(\"cod_variavel\", col(\"cod_variavel\").cast(IntegerType())) \\\n",
    "           .withColumn(\"cod_ano\", col(\"cod_ano\").cast(IntegerType())) \\\n",
    "           .withColumn(\"ano\", col(\"ano\").cast(IntegerType())) \\\n",
    "           .withColumn(\"cod_doenca\", col(\"cod_doenca\").cast(IntegerType())) \\\n",
    "           .withColumn(\"cod_medida\", col(\"cod_medida\").cast(IntegerType())) \\\n",
    "           .withColumn(\"cod_nivel_territorial\", col(\"cod_nivel_territorial\").cast(IntegerType())) \\\n",
    "           .withColumn(\"valor\", col(\"valor\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escrevendo um arquivo JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.write\\\n",
    "    .option(\"compression\", \"gzip\")\\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"json\") \\\n",
    "    .save(\"/FileStore/tables/arquivos_curso/json_gzip/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "  .option(\"compression\", \"gzip\") \\\n",
    "  .json(\"/FileStore/tables/arquivos_curso/json_gzip/\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .format(\"csv\") \\\n",
    "  .save(\"/FileStore/tables/arquivos_curso/pnsb_csv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/pnsb_csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo um arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = spark.read.csv('/FileStore/tables/arquivos_curso/pnsb_csv')\n",
    "display(df_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .option(\"header\", True) \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .format(\"csv\") \\\n",
    "  .save(\"/FileStore/tables/arquivos_curso/pnsb_csv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = spark.read.csv('/FileStore/tables/arquivos_curso/pnsb_csv', header=True, inferSchema=True)\n",
    "display(df_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escrevendo arquivo CSV com compress√£o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.write \\\n",
    "  .option(\"compression\", \"gzip\") \\\n",
    "  .option(\"header\",\"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .format(\"csv\") \\\n",
    "  .save(\"/FileStore/tables/arquivos_curso/csv_gzip/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/csv_gzip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/pnsb_csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "  .option(\"compression\", \"gzip\") \\\n",
    "  .option(\"header\",\"true\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .csv(\"/FileStore/tables/arquivos_curso/csv_gzip\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TXT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando o DataFrame em txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.fill(value=0, subset=[\"valor\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.text(\"/FileStore/tables/arquivos_curso/txt/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "df_uma_coluna = df.select(concat_ws(\"|\", *df.columns).alias('dados'))\n",
    "display(df_uma_coluna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uma_coluna.write \\\n",
    "    .format(\"text\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"/FileStore/tables/arquivos_curso/txt/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/txt/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = spark.read.format(\"text\") \\\n",
    "  .load(\"/FileStore/tables/arquivos_curso/txt/\")\n",
    "\n",
    "display(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = spark.read \\\n",
    "  .option(\"header\", \"false\") \\\n",
    "  .option(\"delimiter\", \"|\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .format(\"csv\") \\\n",
    "  .load(\"/FileStore/tables/arquivos_curso/txt/\")\n",
    "\n",
    "display(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_2 = df_text.withColumnRenamed(\"_c0\",\"ano\") \\\n",
    "       .withColumnRenamed(\"_c1\",\"cod_ano\") \\\n",
    "       .withColumnRenamed(\"_c2\",\"cod_doenca\") \\\n",
    "       .withColumnRenamed(\"_c3\",\"cod_medida\") \\\n",
    "       .withColumnRenamed(\"_c4\",\"cod_nivel_territorial\") \\\n",
    "       .withColumnRenamed(\"_c5\",\"cod_regiao\") \\\n",
    "       .withColumnRenamed(\"_c6\",\"cod_variavel\") \\\n",
    "       .withColumnRenamed(\"_c7\",\"doenca\") \\\n",
    "       .withColumnRenamed(\"_c8\",\"medida\") \\\n",
    "       .withColumnRenamed(\"_c9\",\"nivel_territorial\") \\\n",
    "       .withColumnRenamed(\"_c10\",\"regiao\") \\\n",
    "       .withColumnRenamed(\"_c11\",\"valor\") \\\n",
    "       .withColumnRenamed(\"_c12\",\"variavel\")\n",
    "\n",
    "display(df_text_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando o arquivo txt comprimido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_2.write \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"compression\", \"gzip\") \\\n",
    "  .format(\"text\") \\\n",
    "  .save(\"dbfs:/FileStore/tables/arquivos_curso/txt_gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uma_coluna.write \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"compression\", \"gzip\") \\\n",
    "  .format(\"text\") \\\n",
    "  .save(\"dbfs:/FileStore/tables/arquivos_curso/txt_gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/txt_gzip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/txt/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "  .option(\"compression\", \"gzip\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"sep\", \"|\") \\\n",
    "  .csv(\"/FileStore/tables/arquivos_curso/txt_gzip\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renomeado = df.withColumnRenamed(\"_c0\",\"ano\") \\\n",
    "       .withColumnRenamed(\"_c1\",\"cod_ano\") \\\n",
    "       .withColumnRenamed(\"_c2\",\"cod_doenca\") \\\n",
    "       .withColumnRenamed(\"_c3\",\"cod_medida\") \\\n",
    "       .withColumnRenamed(\"_c4\",\"cod_nivel_territorial\") \\\n",
    "       .withColumnRenamed(\"_c5\",\"cod_regiao\") \\\n",
    "       .withColumnRenamed(\"_c6\",\"cod_variavel\") \\\n",
    "       .withColumnRenamed(\"_c7\",\"doenca\") \\\n",
    "       .withColumnRenamed(\"_c8\",\"medida\") \\\n",
    "       .withColumnRenamed(\"_c9\",\"nivel_territorial\") \\\n",
    "       .withColumnRenamed(\"_c10\",\"regiao\") \\\n",
    "       .withColumnRenamed(\"_c11\",\"valor\") \\\n",
    "       .withColumnRenamed(\"_c12\",\"variavel\")\n",
    "\n",
    "display(df_renomeado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renomeado.write \\\n",
    "  .mode(\"overwrite\")\\\n",
    "  .format('avro') \\\n",
    "  .save(\"/FileStore/tables/arquivos_curso/avro/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/avro/\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVRO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo um arquivo no formato AVRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avro = spark.read \\\n",
    "        .format(\"avro\") \\\n",
    "        .load(\"/FileStore/tables/arquivos_curso/avro\")\n",
    "\n",
    "display(df_avro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avro = spark.read \\\n",
    "        .format(\"avro\") \\\n",
    "        .load(\"/FileStore/tables/arquivos_curso/avro/\", pathGlobFilter=\"*.avro\")\n",
    "\n",
    "display(df_avro)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escrevendo o arquivo AVRO com compress√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avro.write \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"compression\", \"deflate\") \\\n",
    "  .format('avro') \\\n",
    "  .save(\"/FileStore/tables/arquivos_curso/avro_deflate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/avro_deflate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/avro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.avro.compression.codec\", \"deflate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avro.write \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .format('avro') \\\n",
    "  .save(\"/FileStore/tables/arquivos_curso/avro_deflate2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/avro_deflate2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.avro.deflate.level\", \"8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avro.write \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .format('avro') \\\n",
    "  .save(\"/FileStore/tables/arquivos_curso/avro_deflate2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/avro_deflate2\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARQUET"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo e escrevendo arquivos PARQUET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avro.write \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .format('parquet') \\\n",
    "  .save(\"/FileStore/tables/arquivos_curso/parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avro.write \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"compression\", \"gzip\") \\\n",
    "  .format('parquet') \\\n",
    "  .save(\"/FileStore/tables/arquivos_curso/parquet_gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/parquet_gzip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = spark.read.format(\"parquet\") \\\n",
    "  .load(\"/FileStore/tables/arquivos_curso/parquet_gzip\", compression='gzip')\n",
    "\n",
    "display(df_parquet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particionamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet.select(\"cod_doenca\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet.select(\"nivel_territorial\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet.write\\\n",
    "    .partitionBy(\"nivel_territorial\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .parquet(\"/FileStore/tables/arquivos_curso/parquet_particionado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/parquet_particionado\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/parquet_particionado/nivel_territorial=Brasil\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet.write\\\n",
    "    .partitionBy(\"nivel_territorial\", \"cod_doenca\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .parquet(\"/FileStore/tables/arquivos_curso/parquet_multi_particionado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"FileStore/tables/arquivos_curso/parquet_multi_particionado\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/parquet_multi_particionado/nivel_territorial=Grande Regi√£o/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_120943 = spark.read\\\n",
    "     .parquet('/FileStore/tables/arquivos_curso/parquet_multi_particionado/nivel_territorial=Grande Regi√£o/cod_doenca=120943/')\n",
    "\n",
    "\n",
    "display(df_120943)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "    .parquet('/FileStore/tables/arquivos_curso/parquet_particionado')\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escrevendo e lendo arquivos ORC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write \\\n",
    "  .format('orc') \\\n",
    "  .save(\"/FileStore/tables/arquivos_curso/orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/orc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"orc\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"compression\", \"zlib\") \\\n",
    "    .save(\"/FileStore/tables/arquivos_curso/orc_zlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/orc_zlib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orc = spark.read\\\n",
    "  .option(\"compression\", \"zlib\") \\\n",
    "  .format(\"orc\") \\\n",
    "  .load(\"/FileStore/tables/arquivos_curso/orc_zlib\")\n",
    "\n",
    "display(df_orc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupando as parti√ß√µes criadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orc.coalesce(1)\\\n",
    " .write \\\n",
    " .format(\"orc\") \\\n",
    " .mode(\"overwrite\") \\\n",
    " .save(\"/FileStore/tables/arquivos_curso/orc_junto_snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/orc_junto_snappy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orc.coalesce(1)\\\n",
    " .write \\\n",
    " .format(\"orc\") \\\n",
    " .mode(\"overwrite\") \\\n",
    " .option(\"compression\", \"zlib\") \\\n",
    " .save(\"/FileStore/tables/arquivos_curso/orc_junto_zlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/arquivos_curso/orc_junto_zlib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orc_zlib = spark.read \\\n",
    "  .option(\"compression\", \"zlib\") \\\n",
    "  .orc(\"/FileStore/tables/arquivos_curso/orc_junto_zlib\")\n",
    "\n",
    "display(df_orc_zlib)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59b23a439ce858f6c48b87cdc3961c05fe34c6c004d414990b7e953144d53d79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
